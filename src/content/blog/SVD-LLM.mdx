---
heroImage: /src/assets/Screenshot 2024-12-12 094814.png
category: 学习
description: >-
  对论文《SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language
  Model Compression》的阅读记录
pubDate: 2024-12-11T16:00:00.000Z
draft: false
tags:
  - llm
  - decomposition
  - svd
title: 论文《SVD-LLM》的阅读记录
---

# SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression

链接：[https://arxiv.org/abs/2403.07378](https://arxiv.org/abs/2403.07378)

## 1.发现的问题：

1. 模糊的数据预处理：尽管[ASVD](https://arxiv.org/abs/2312.05821)提出的数据预处理策略减少了异常激活值的负面影响，但它并未在奇异值与模型压缩损失值之间建立直接关系
2. SVD截断后的模型参数不会更新：为了补偿因截断大量奇异值而导致的精度下降，需要更新压缩模型中剩余的参数。但现有的基于SVD的大模型压缩方法并未考虑这种更新，因此在高模型压缩比下无法补偿精度下降。

## 2.解决方法：

1. 截断感知的数据白化：采用了一种截断感知的数据白化技术，确保奇异值与模型压缩损失之间存在直接映射。通过这种方式，所提出的截断感知数据白化技术能够识别出哪些奇异值应该被截断以最小化模型压缩损失
   1. **白化变换**（Whitening transformation），也被成为**球化变换**，是一种**线性变换**。它将已知协方差矩阵的随机变量向量变换为一组新的变量，这些变量的协方差为单位矩阵，这意味着它们是不相关的，每个变量的方差为1。其**主要目的**是：**去除数据之间的相关性**，使变换后的数据特征之间相互独立；**标准化方差**，使所有特征具有相同的方差（通常是单位方差）。**具体效果**是：将原始数据转换成**均值为0**，**协方差矩阵为单位矩阵**的新数据。变换后的数据看起来就像"白噪声"，因此称为**白化**。
2. 逐层闭合形式模型参数更新：为了补偿高压缩比下精度的下降，采用了一种逐层闭合形式的模型参数更新策略，以逐层渐进地更新压缩后的权重。

## 3.其他细节

1. 弗罗贝尼乌斯范数（Frobenius norm）![](<../../assets/屏幕截图 2024-12-16 093414.png>)
2. Frobenius 范数误差E![](<../../assets/屏幕截图 2024-12-16 093639.png>)![](<../../assets/屏幕截图 2024-12-16 093954.png>)
3. 科列斯基分解（Cholesky decomposition）

## 4.问题
